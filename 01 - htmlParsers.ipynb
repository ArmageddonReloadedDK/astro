{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Спарсим рамблер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это работает так: сначала код запрашивает требуемую страинцу у рамблера, тот в ответ отправляет html страницу, а затем идет поиск тега, в котором находится текст гороскопа. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signs=['aries','gemini','taurus','cancer','leo','virgo','libra','scorpio','sagittarius','capricorn','aquarius','pisces']\n",
    "data = pd.read_csv('data.csv', names=['date', 'sign', 'text'])\n",
    "\n",
    "for i in range(2004,2021):\n",
    "    for j in range(1,13):\n",
    "        for k in range(1,32):\n",
    "            for sign in signs:\n",
    "                try:\n",
    "                    year=i\n",
    "                    month=j\n",
    "                    day=k\n",
    "                    if month<10:\n",
    "                        month='0'+str(month)\n",
    "                    if day<10:\n",
    "                        day='0'+str(day)\n",
    "                    date='%s-%s-%s'%(year,month,day)\n",
    "                    url = 'https://horoscopes.rambler.ru/%s/%s/?updated'% (sign,date)  # url для второй страницы\n",
    "                    print(url)\n",
    "                    r = requests.get(url)\n",
    "                    response = r.text.encode('utf-8')\n",
    "\n",
    "                    soup = BeautifulSoup(response, features=\"lxml\")\n",
    "                    text = soup.find('div', {'class': '_1dQ3'}).text\n",
    "                    data=data.append({'date': date, 'sign': sign, 'text': text}, ignore_index=True)\n",
    "                    data.to_csv('data.csv', encoding = 'utf-8')\n",
    "                    print('saved date=', date, ' sign=', sign)\n",
    "                except Exception:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сайт Ростова-на-Дону"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.1rnd.ru/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news=[]\n",
    "url='https://www.1rnd.ru/news/3089599'\n",
    "print(url)\n",
    "r = requests.get(url)\n",
    "response = r.text\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "news_text=soup.findAll('p', {'style': \"text-align:justify;\"})\n",
    "date_text=soup.findAll('div', {'class': \"article-info__time\"})\n",
    "header_text=soup.findAll('div',{'class':'title-container inner-title'})\n",
    "\n",
    "if news_text:\n",
    "    print('success')\n",
    "    text_line=''\n",
    "    for text in news_text:\n",
    "         text_line=text_line+text.get_text()\n",
    "    news.append([header_text[0].get_text(),date_text[0].get_text().split(),text_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.DataFrame({'header': [0], 'date': [0], 'news': [0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start1=7135\n",
    "start2=300000\n",
    "start3=600000\n",
    "start4=900000\n",
    "start5=1200000\n",
    "start6=1500000\n",
    "start7=1800000\n",
    "start8=2100000\n",
    "start9=2400000\n",
    "start10=2700000\n",
    "\n",
    "end1=299999\n",
    "end2=599999\n",
    "end3=899999\n",
    "end4=1199999\n",
    "end5=1499999\n",
    "end6=1799999\n",
    "end7=2099999\n",
    "end8=2399999\n",
    "end9=2699999\n",
    "end10=2999999\n",
    "\n",
    "\n",
    "async def get_news(start,end):\n",
    "    global news\n",
    "    for i in range(start,end):\n",
    "        url ='https://www.1rnd.ru/news/{0}'.format(str(i)) \n",
    "        print(url)\n",
    "        \n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url) as response:\n",
    "\n",
    "                response = await response.text()\n",
    "                soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "                news_text=soup.findAll('p', {'style': \"text-align:justify;\"})\n",
    "                date_text=soup.findAll('div', {'class': \"article-info__time\"})\n",
    "                header_text=soup.findAll('div',{'class':'title-container inner-title'})\n",
    "\n",
    "                if news_text:\n",
    "                    print('success')\n",
    "                    text_line=''\n",
    "                    for text in news_text:\n",
    "                         text_line=text_line+text.get_text()\n",
    "                            \n",
    "                    date=date_text[0].get_text()\n",
    "                    header=header_text[0].get_text()\n",
    "\n",
    "                    news=news.append({'header': header, 'date': date, 'news': text_line}, ignore_index=True)\n",
    "                    news.to_csv('news.csv', encoding = 'utf-8')\n",
    "\n",
    "futures = [get_news(start1,end1),\n",
    "           get_news(start2,end2),\n",
    "           get_news(start3,end3),\n",
    "           get_news(start4,end4),\n",
    "           get_news(start5,end5),\n",
    "           get_news(start6,end6),\n",
    "           get_news(start7,end7),\n",
    "           get_news(start8,end8),\n",
    "           get_news(start9,end9),\n",
    "           get_news(start10,end10)]\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(asyncio.wait(futures))\n",
    "loop.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# BookYogaRetreats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "page=1\n",
    "base_url='www.bookyogaretreats.com'\n",
    "url = f'https://{base_url}/?page={page}'\n",
    "print(url)\n",
    "r = requests.get(url)\n",
    "response = r.text.encode('utf-8')\n",
    "\n",
    "soup = BeautifulSoup(response)\n",
    "text = soup.findAll('a', {'class': 'js-showcard-link'},href=True)\n",
    "card_urls=[]\n",
    "for t in text:\n",
    "    card_urls.append(t['href'])\n",
    "# data=data.append({'date': date, 'sign': sign, 'text': text}, ignore_index=True)\n",
    "# data.to_csv('data.csv', encoding = 'utf-8')\n",
    "# print('saved date=', date, ' sign=', sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=1\n",
    "base_url='www.bookyogaretreats.com'\n",
    "url = f'https://{base_url}{card_urls[0]}'\n",
    "print(url)\n",
    "r = requests.get(url)\n",
    "response = r.text.encode('utf-8')\n",
    "\n",
    "soup = BeautifulSoup(response,'html.parser')\n",
    "text = soup.findAll('a', {'class': 'js-showcard-link'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "класс массива карточек: cards cards--new-showcards\n",
    "\n",
    "класс одной карточки: js-showcard-link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "название ретрита: listing-title__title title listing-title-new\n",
    "\n",
    "длительность: subtitle-small listing-query-box__duration js-sc3-inquiry-modal-duration js-insert-duration\n",
    "\n",
    "цена: listing-query-box__price price-wrapper listing-query-box__price__flexible-duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll('span', {'class': 'price'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "duration=soup.findAll('div', {'class': 'subtitle-small listing-query-box__duration js-sc3-inquiry-modal-duration js-insert-duration'})[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "driver = webdriver.Firefox(executable_path= r\"D:\\загрузки\\geckodriver-v0.30.0-win64\\geckodriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.bookyogaretreats.com/luxury-executive-wellness/6-day-luxury-wellness-yoga-retreat-in-santa-barbara-florida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_elements_by_class_name('price')[0].text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
