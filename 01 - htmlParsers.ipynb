{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import time\n",
    "from fake_useragent import UserAgent\n",
    "from collections import Counter\n",
    "import urllib\n",
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Спарсим рамблер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signs = ['aries', 'gemini', 'taurus', 'cancer', 'leo', 'virgo', 'libra', 'scorpio', 'sagittarius', 'capricorn',\n",
    "         'aquarius', 'pisces']\n",
    "data = pd.read_csv('data.csv', names=['date', 'sign', 'text'])\n",
    "\n",
    "for i in range(2004, 2021):\n",
    "    for j in range(1, 13):\n",
    "        for k in range(1, 32):\n",
    "            for sign in signs:\n",
    "                try:\n",
    "                    year = i\n",
    "                    month = j\n",
    "                    day = k\n",
    "                    if month < 10:\n",
    "                        month = '0' + str(month)\n",
    "                    if day < 10:\n",
    "                        day = '0' + str(day)\n",
    "                    date = '%s-%s-%s' % (year, month, day)\n",
    "                    url = 'https://horoscopes.rambler.ru/%s/%s/?updated' % (sign, date)  # url для второй страницы\n",
    "                    print(url)\n",
    "                    r = requests.get(url)\n",
    "                    response = r.text.encode('utf-8')\n",
    "\n",
    "                    soup = BeautifulSoup(response, features=\"lxml\")\n",
    "                    text = soup.find('div', {'class': '_1dQ3'}).text\n",
    "                    data = data.append({'date': date, 'sign': sign, 'text': text}, ignore_index=True)\n",
    "                    data.to_csv('data.csv', encoding='utf-8')\n",
    "                    print('saved date=', date, ' sign=', sign)\n",
    "                except Exception:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сайт Ростова-на-Дону"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.1rnd.ru/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "url = 'https://www.1rnd.ru/news/3089599'\n",
    "print(url)\n",
    "r = requests.get(url)\n",
    "response = r.text\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "news_text = soup.findAll('p', {'style': \"text-align:justify;\"})\n",
    "date_text = soup.findAll('div', {'class': \"article-info__time\"})\n",
    "header_text = soup.findAll('div', {'class': 'title-container inner-title'})\n",
    "\n",
    "if news_text:\n",
    "    print('success')\n",
    "    text_line = ''\n",
    "    for text in news_text:\n",
    "        text_line = text_line + text.get_text()\n",
    "    news.append([header_text[0].get_text(), date_text[0].get_text().split(), text_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "news = pd.DataFrame({'header': [0], 'date': [0], 'news': [0]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start1 = 7135\n",
    "start2 = 300000\n",
    "start3 = 600000\n",
    "start4 = 900000\n",
    "start5 = 1200000\n",
    "start6 = 1500000\n",
    "start7 = 1800000\n",
    "start8 = 2100000\n",
    "start9 = 2400000\n",
    "start10 = 2700000\n",
    "\n",
    "end1 = 299999\n",
    "end2 = 599999\n",
    "end3 = 899999\n",
    "end4 = 1199999\n",
    "end5 = 1499999\n",
    "end6 = 1799999\n",
    "end7 = 2099999\n",
    "end8 = 2399999\n",
    "end9 = 2699999\n",
    "end10 = 2999999\n",
    "\n",
    "\n",
    "async def get_news(start, end):\n",
    "    global news\n",
    "    for i in range(start, end):\n",
    "        url = 'https://www.1rnd.ru/news/{0}'.format(str(i))\n",
    "        print(url)\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url) as response:\n",
    "\n",
    "                response = await response.text()\n",
    "                soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "                news_text = soup.findAll('p', {'style': \"text-align:justify;\"})\n",
    "                date_text = soup.findAll('div', {'class': \"article-info__time\"})\n",
    "                header_text = soup.findAll('div', {'class': 'title-container inner-title'})\n",
    "\n",
    "                if news_text:\n",
    "                    print('success')\n",
    "                    text_line = ''\n",
    "                    for text in news_text:\n",
    "                        text_line = text_line + text.get_text()\n",
    "\n",
    "                    date = date_text[0].get_text()\n",
    "                    header = header_text[0].get_text()\n",
    "\n",
    "                    news = news.append({'header': header, 'date': date, 'news': text_line}, ignore_index=True)\n",
    "                    news.to_csv('news.csv', encoding='utf-8')\n",
    "\n",
    "\n",
    "futures = [get_news(start1, end1),\n",
    "           get_news(start2, end2),\n",
    "           get_news(start3, end3),\n",
    "           get_news(start4, end4),\n",
    "           get_news(start5, end5),\n",
    "           get_news(start6, end6),\n",
    "           get_news(start7, end7),\n",
    "           get_news(start8, end8),\n",
    "           get_news(start9, end9),\n",
    "           get_news(start10, end10)]\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(asyncio.wait(futures))\n",
    "loop.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "torch",
   "language": "python",
   "display_name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}