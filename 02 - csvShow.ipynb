{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pymorphy2\n",
    "import matplotlib as mpl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Очистка данных\n",
    "\n",
    "Так как при парсинге могут возникнуть ошибки, то очистим текстовые данные от пропусков, эмодзи, непонятных знаков и тд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удалим пропуски и сверхкороткие строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i=len(data)-1\n",
    "while i >0: \n",
    "    print(i)\n",
    "    text=str(data['text'][i])\n",
    "    sign=str(data['sign'][i])\n",
    "    date=str(data['date'][i])\n",
    "    if len(sign)<2:\n",
    "        data=data.drop([i])\n",
    "        print('deleted sign',i)\n",
    "    if len(text)<2:\n",
    "        data=data.drop([i])\n",
    "        print('deleted text',i)\n",
    "    if len(date)>13:\n",
    "        data=data.drop([i])\n",
    "        print('deleted date',i)\n",
    "    if date[0]!=\"2\":\n",
    "        data=data.drop([i])\n",
    "        print('deleted num2',i)\n",
    "    i-=1 \n",
    "\n",
    "chars = set([c for c in text]) # создадим множество из слов, т.е. словарь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удалим из текста все, что не текст "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dataset.shape[0]):\n",
    "    text=str(dataset[i][2])\n",
    "    text=text.replace('.','')\n",
    "    text=text.replace(',','')\n",
    "    text=text.replace(')','')\n",
    "    text=text.replace('(','')\n",
    "    text=text.replace('»','')\n",
    "    text=text.replace('«','')\n",
    "    text=text.replace('\"','')\n",
    "    text=text.replace(':','')\n",
    "    text=text.replace('-',' ')\n",
    "    text=text.replace('!','')\n",
    "    text=text.lower()\n",
    "    dataset[i][2]=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создадим словарь из слов датасета, приведенных к именительному падежу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_words=set()\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dataset.shape[0]):\n",
    "    text=str(dataset[i][2])\n",
    "    text_chars=text.split(' ')\n",
    "    for  word in text_chars:\n",
    "        raw_words.add(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохраним множество слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list=[]\n",
    "for word in raw_words:\n",
    "    words_list.append({'word':word})\n",
    "\n",
    "words_df=pd.DataFrame(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_df.to_csv('words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посчитаем количество повторений \n",
    "\n",
    "То есть посчитаем для каждого слова в каком предложении и сколько раз потворялось. Такой массив имеет размерность \n",
    "\n",
    "(количество_предложений, размер_словаря)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=pd.read_csv('words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_set=set()\n",
    "for i,word in enumerate(chars):\n",
    "    text=morph.parse(word[0])[0].normal_form\n",
    "    chars_set.add(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signs_set=set()\n",
    "for line in dataset:\n",
    "    signs_set.add(line[1])\n",
    "signs_list=[sign for sign in signs_set]\n",
    "chars_list=[char for char in chars_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data=np.zeros((len(chars_list),len(signs_list)))\n",
    "for i,line in enumerate(dataset):\n",
    "    sign=line[1]\n",
    "    text=str(line[2])\n",
    "    text=text.split(' ')\n",
    "    for word in text:\n",
    "        if word=='':\n",
    "            continue\n",
    "        fixed=morph.parse(word)[0].normal_form\n",
    "        x=chars_list.index(fixed)\n",
    "        y=signs_list.index(sign)\n",
    "        stat_data[x][y]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('stat_data', stat_data)\n",
    "np.save('signs_list', signs_list)\n",
    "np.save('chars_list', chars_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выведем полученные статистические данные на диаграмму\n",
    "\n",
    "Статистика получилась интересная. \n",
    "Например, для всех знаков зодиака повторяются первые 10+-2 слов. Также после набора \"повторяющихся\" слова идет один определенный знак зодиака. Для каждого знака он свой. Это можно интерпретироват как то, что либо у всех знаков есть свой \"подходящий знак\", либо то,что есть уже заготовленные правила написания гороскопов.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data = np.load('parsedArrays/stat_data.npy')\n",
    "signs = np.load('parsedArrays/signs_list.npy')\n",
    "\n",
    "stat_data_list=list(stat_data)\n",
    "chars_list = list(np.load('parsedArrays/chars_list.npy'))\n",
    "signs={'aries':0,'gemini':1,'taurus':2,'cancer':3,'leo':4,'virgo':5,'libra':6,\n",
    "       'scorpio':7,'sagittarius':8,'capricorn':9,'aquarius':10,'pisces':11}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Можно поиграться с другими знаками\n",
    "\n",
    "Для этого нужно поменять переменную sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign='aries'  # можно тут поменять знак зодиака на другой, чтобы вывести соответсвующую диаграмму\n",
    "groups = [i for i in range(len(chars_list))]\n",
    "counts = np.array([num[signs[sign]] for num in stat_data])\n",
    "counts_list=list(counts)\n",
    "sum=counts.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.sort(axis=0)\n",
    "N=100\n",
    "common_vals=counts[::-1]\n",
    "common_vals=common_vals[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_indeces=[]\n",
    "\n",
    "for val in common_vals:\n",
    "    key=counts_list.index(val)\n",
    "    common_indeces.append(key)\n",
    "    \n",
    "common_words=[]\n",
    "\n",
    "for index in common_indeces:\n",
    "    common_words.append(chars_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi = 150\n",
    "fig = plt.figure(dpi = dpi, figsize = (1024 / dpi, 2048 / dpi) )\n",
    "mpl.rcParams.update({'font.size': 9})\n",
    "\n",
    "plt.title('Относительная частота появления слов')\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.xaxis.grid(True, zorder = 1)\n",
    "\n",
    "x=range(N)\n",
    "y=common_vals/sum\n",
    "\n",
    "plt.barh(x, y, height = 0.2, color = 'red', label=sign ,alpha = 0.7, zorder =2)\n",
    "plt.yticks(range(len(common_words)), common_words, rotation = 1)\n",
    "plt.legend(loc='upper right')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_neuro",
   "language": "python",
   "name": "env_neuro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}